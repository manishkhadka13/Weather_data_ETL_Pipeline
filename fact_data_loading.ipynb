{"cells":[{"cell_type":"code","source":["@logs\ndef hourly_weather(df):\n    from pyspark.sql.functions import hour,col,lit\n    from datetime import datetime\n    df=df.withColumn('timeid',hour('created_on')).withColumn('Datex',col('created_on').cast('date'))\n    try:\n        timeid,date=df.select('timeid','Datex').first()\n        dateid=str(date).replace('-','')\n        query=f\"Delete from fact_hourly_weather where time_id='{timeid}' and Date_id='{dateid}';\"\n        spark.sql(query)\n    except:\n        pass\n    for row in df.rdd.collect():\n        date_str = row.date\n\n        # Split the date column into separate date and time components\n        date_time = date_str.split(\" \")\n        date_id = date_time[0].replace(\"-\", \"\")\n        time_id = int(date_time[1].split(\":\")[0])\n\n        # Perform further processing or store the extracted date_id and time_id as desired\n        df = df.withColumn(\"date_id\", lit(date_id))\n        df = df.withColumn(\"time_id\",lit(time_id))\n        \n    date_df=spark.table('dim_date')\n    time_df=spark.table('dim_time')\n\n    joined_df = df.join(date_df, df['date_id'] == date_df['Date_id'], 'inner')\\\n    .join(time_df, df['time_id'] == time_df['time_id'], 'inner')\\\n    .select(df['date_id'], df['date'], df['dt'], df['time_id'], df['city_id'], df['temp'], df['timezone'], df['temp_min'], df['temp_max'], df['pressure'], df['humidity'], df['visibility'],df['load_run_id'],df['created_on'],df['created_by'])\n    start = datetime.fromtimestamp(df.selectExpr(\"min(dt)\").first()[0])\n    end = datetime.fromtimestamp(df.selectExpr(\"max(dt)\").first()[0])\n    \n    return joined_df,start,end\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"60469995-90ab-4860-9051-b5456c398818","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["@logs\ndef daily_weather(df):\n    from datetime import datetime\n    from pyspark.sql.functions import hour, col, min, max, mean\n    df=df.withColumn(\"Date\",col(\"created_on\").cast(\"date\"))\n    date_df=spark.table(\"dim_date\")\n    joined_df=df.join(date_df,df['date']==date_df['fullDate'],'inner').select(\n                        date_df.Date_id,\n                        df.city_id,\n                        df.dt,\n                        df.temp,\n                        df.timezone,\n                        df.temp,\n                        df.temp_min,\n                        df.temp_max,\n                        df.pressure,\n                        df.humidity,\n                        df.visibility,\n                      )\n    daily_df=joined_df.alias('daily_df')\n    try:\n        date=df.select('Date').first()\n        date_id=str(date).replace('-','')\n        daily_df = spark.sql(f\"select * from fact_daily_weather where Date_id='{date_id}';\")\\\n                        .drop('load_run_id', 'created_on', 'created_by')\n        spark.sql(f\"delete from fact_daily_weather where Date_id='{date_id}';\")\n    except:\n        pass\n    \n    fact_df=joined_df.union(daily_df).groupBy(col('city_id'),col('date_id')) \\\n                .agg(mean('temp').alias('temp'),\n                    min('temp_min').alias('temp_min'),\n                    max('temp_max').alias('temp_max'),\n                    mean('pressure').cast('int').alias('pressure'),\n                    mean('timezone').cast('int').alias('timezone'),\n                    mean('humidity').cast('int').alias('humidity'),\n                    mean('visibility').cast('int').alias('visibility'),\n                   )\n    start = datetime.fromtimestamp(df.selectExpr(\"min(dt)\").first()[0])\n    end = datetime.fromtimestamp(df.selectExpr(\"max(dt)\").first()[0])\n    \n    return fact_df,start,end\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"98f9565d-ee12-4b62-9282-33707426d7be","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"fact_data_loading","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
