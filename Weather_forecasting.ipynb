{"cells":[{"cell_type":"code","source":["@logs\ndef forecasted_data(df):\n    from datetime import datetime,timedelta\n    from pyspark.sql.functions import hour,col,lit,min,max,round,mean\n    df=df.withColumn('time_id',hour('created_on')).withColumn('date',col('created_on').cast('date'))\n    time_id,date=df.select('time_id','date').first()\n    date_id=str(date).replace('-','')\n    try:\n        query=f\"Delete from fact_hourly_weather where time_id>='{time_id}' and date_id>='{date_id}';\"\n        spark.sql(query)\n    except:\n        pass\n    date_df=spark.table('dim_date')\n    time_df=spark.table('dim_time')\n    \n    joined_df = df.join(date_df, df['date'] == date_df['fullDate'], 'inner')\\\n    .join(time_df, df['time_id'] == time_df['time_id'], 'inner')\\\n    .select(date_df['Date_id'], df['date'], df['dt'], df['time_id'], df['city_id'], df['temp'], df['timezone'], df['temp_min'], df['temp_max'], df['pressure'], df['humidity'], df['visibility'])\n    \n    fact_df=joined_df.withColumn(\"IsForecasted\",lit('false'))\\\n            .select('time_id','date_id','city_id','temp','temp_min','temp_max','pressure','humidity','visibility','IsForecasted')\n    \n    for i in range(1,4):\n        ref_time=(time_id-i)%24\n        off_date=int((time_id-i)//24)\n        ref_date=date+timedelta(off_date)\n        ref_date=str(ref_date).replace('-','')\n        \n        try:\n            query=f\"select * from fact_hourly_weather where time_id='{ref_time}' and date_id='{ref_date}'\"\\\n                    .drop('load_run_id','created_on','created_by')\n            df1=spark.sql(query)\n            fact_df=fact_df.union(df1)\n        except:\n            pass\n        \n    for i in range(1,4):\n        ref_time=(time_id+i)%24\n        off_date=int((time_id+i)//24)\n        ref_date=date+timedelta(off_date)\n        ref_date=str(ref_date).replace('-','')\n\n        forecasted_df=fact_df.groupBy(col('city_id'),col('date_id'))\\\n                    .agg(round(mean('temp'),2).alias('temp'),\n                         min('temp_min').alias('temp_min'),\n                         max('temp_max').alias('temp_max'),\n                         mean('pressure').cast('int').alias('pressure'),\n                         mean('humidity').cast('int').alias('humidity'),\n                         mean('visibility').cast('int').alias('visibility'), \n                       )\n        forecasted_df=forecasted_df.withColumn('time_id',lit(ref_time)).withColumn('date_id',lit(ref_date)).withColumn('IsForecasted',lit('true'))\\\n                        .select('time_id', 'date_id', 'city_id', 'temp', 'temp_min', 'temp_max', 'pressure', 'humidity', 'visibility','IsForecasted')\n        fact_df=fact_df.union(forecasted_df)\n        not_ref=(ref_time-4)%24\n        fact_df=fact_df.filter(fact_df.time_id!=not_ref)\n            \n    start = datetime.fromtimestamp(df.selectExpr(\"min(dt)\").first()[0])\n    end = datetime.fromtimestamp(df.selectExpr(\"max(dt)\").first()[0])\n    \n    return fact_df,start,end\n        "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"0035be8b-cc09-4d76-bd66-83a0ae66584b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-3089831312894099>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;129m@logs\u001B[39m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforecasted_data\u001B[39m(df):\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datetime,timedelta\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m hour,col,lit,\u001B[38;5;28mmin\u001B[39m,\u001B[38;5;28mmax\u001B[39m,\u001B[38;5;28mround\u001B[39m,mean\n\n\u001B[0;31mNameError\u001B[0m: name 'logs' is not defined","errorSummary":"<span class='ansi-red-fg'>NameError</span>: name 'logs' is not defined","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n","\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n","File \u001B[0;32m<command-3089831312894099>:1\u001B[0m\n","\u001B[0;32m----> 1\u001B[0m \u001B[38;5;129m@logs\u001B[39m\n","\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforecasted_data\u001B[39m(df):\n","\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datetime,timedelta\n","\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m hour,col,lit,\u001B[38;5;28mmin\u001B[39m,\u001B[38;5;28mmax\u001B[39m,\u001B[38;5;28mround\u001B[39m,mean\n","\n","\u001B[0;31mNameError\u001B[0m: name 'logs' is not defined"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Weather_forecasting","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
